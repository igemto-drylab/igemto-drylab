{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UniRep.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "4zxS7bYDXxNB"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMcJA6bxbTIPHToxo4AFXVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igemto-drylab/igemto-drylab/blob/master/Track-2/UniRep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdtz4_tN9u78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi #make sure to have a tesla p100 to use unirep properly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKaq_pFUOrSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "#installing aws interaction to get weight files\n",
        "!pip install awscli"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZr8uOu8mKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the github repo\n",
        "push_acc = input(\"push access? (y/n):\")\n",
        "\n",
        "if push_acc == \"y\":\n",
        "\n",
        "    from getpass import getpass\n",
        "\n",
        "    password = getpass(\"type password:\")\n",
        "    !git clone https://epicrunze:{password}@github.com/epicrunze/UniRep.git \n",
        "\n",
        "else:\n",
        "\n",
        "    !git clone https://github.com/epicrunze/UniRep.git \n",
        "%cd UniRep\n",
        "!git pull\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEjpehWIFI27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#selecting a working version of tensorflow\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3UiDQxhZXB",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEkBhb25Xm0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_FULL_1900_DIM_MODEL = True # if True use 1900 dimensional model, else use 64 dimensional one."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyHRsafxXsoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__) #should be  1.15\n",
        "\n",
        "# Set seeds\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "if USE_FULL_1900_DIM_MODEL:\n",
        "    # Sync relevant weight files\n",
        "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/1900_weights/ 1900_weights/\n",
        "    \n",
        "    # Import the mLSTM babbler model\n",
        "    from unirep import babbler1900 as babbler\n",
        "    \n",
        "    # Where model weights are stored.\n",
        "    MODEL_WEIGHT_PATH = \"./1900_weights\"\n",
        "    \n",
        "else:\n",
        "    # Sync relevant weight files\n",
        "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
        "    \n",
        "    # Import the mLSTM babbler model\n",
        "    from unirep import babbler64 as babbler\n",
        "    \n",
        "    # Where model weights are stored.\n",
        "    MODEL_WEIGHT_PATH = \"./64_weights\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UWdQWkVVrdJ",
        "colab_type": "text"
      },
      "source": [
        "# Creating a pipeline for converting sequences to unirep vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnGlG7TH7o1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# time to convert sequences to unirep vectors\n",
        "# initialize unirep babbler (lstm network)\n",
        "model = babbler(model_path=MODEL_WEIGHT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5S0KFgWMxoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# defining a directory to pull files out of\n",
        "data_dir = \"/content/UniRep/finished_files/\"\n",
        "# reading csv to dataframe\n",
        "df = pd.read_csv(data_dir + \"humans_with_seq.csv\")\n",
        "# defining a directory to store all the vectors\n",
        "storage_dir = \"/content/UniRep/UniRep_Vecs\"\n",
        "df.head() # displays the 1st 5 rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_yGIpCROCZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting dataframe to a dictionary with column headers as keys, and the values being a list of the columns\n",
        "dfDict = df.to_dict(orient=\"list\")\n",
        "del df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnR3Ydyt_Wda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating functions to write data to folder\n",
        "from time import time\n",
        "\n",
        "sequence_limit = 1000 # due to memory concerns\n",
        "\n",
        "size = len(dfDict[\"proteinID\"]) # size of dataset\n",
        "\n",
        "stepsize = 500 # how many sequences to process in one graph initiation\n",
        "\n",
        "for i in range(0, size, stepsize):\n",
        "    st = time()\n",
        "    cap = i + stepsize if i + stepsize < size else size # making sure we don't go out of index\n",
        "\n",
        "    tempProtIDs = []\n",
        "    tempSeqs = []\n",
        "    for protID, seq in zip(dfDict[\"proteinID\"][i:cap], dfDict[\"sequence\"][i:cap]):\n",
        "        if len(seq) < sequence_limit:\n",
        "            tempProtIDs.append(protID)\n",
        "            tempSeqs.append(seq)\n",
        "\n",
        "\n",
        "    fusionVecs = model.get_rep(tempSeqs)\n",
        "\n",
        "    for protID, vec in zip(tempProtIDs, fusionVecs):\n",
        "        np.save(\"{}/{}.npy\".format(storage_dir, protID), vec)\n",
        "    \n",
        "    del fusionVecs\n",
        "    del tempSeqs\n",
        "\n",
        "    !git add -A;git commit -m \"add {i} to {cap} human vectors\";git push\n",
        "\n",
        "    et = time()\n",
        "\n",
        "    print(\"Process took {} seconds\".format(et-st))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}