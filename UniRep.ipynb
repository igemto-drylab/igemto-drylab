{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UniRep.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1paJtEL9ekLbyGM1tPUrWJNtPlE2YY6PG",
      "authorship_tag": "ABX9TyM2oqO0euEfLiyZqbumg4lf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igemto-drylab/igemto-drylab/blob/master/UniRep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdtz4_tN9u78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi #make sure to have a tesla p100 to use unirep properly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKaq_pFUOrSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "#installing aws interaction to get weight files\n",
        "!pip install awscli"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZr8uOu8mKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the github repo\n",
        "!git clone https://github.com/epicrunze/UniRep.git\n",
        "%cd UniRep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEjpehWIFI27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#installing a working version of tensorflow\n",
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow==1.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEkBhb25Xm0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_FULL_1900_DIM_MODEL = True # if True use 1900 dimensional model, else use 64 dimensional one."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zxS7bYDXxNB",
        "colab_type": "text"
      },
      "source": [
        "# Test Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyHRsafxXsoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__) #should be  1.3.0\n",
        "\n",
        "# Set seeds\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "if USE_FULL_1900_DIM_MODEL:\n",
        "    # Sync relevant weight files\n",
        "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/1900_weights/ 1900_weights/\n",
        "    \n",
        "    # Import the mLSTM babbler model\n",
        "    from unirep import babbler1900 as babbler\n",
        "    \n",
        "    # Where model weights are stored.\n",
        "    MODEL_WEIGHT_PATH = \"./1900_weights\"\n",
        "    \n",
        "else:\n",
        "    # Sync relevant weight files\n",
        "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
        "    \n",
        "    # Import the mLSTM babbler model\n",
        "    from unirep import babbler64 as babbler\n",
        "    \n",
        "    # Where model weights are stored.\n",
        "    MODEL_WEIGHT_PATH = \"./64_weights\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLEf5ijzYqqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 12\n",
        "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaC9jPJTYvKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq = \"MRKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFARYPDHMKQHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs57v6hUYxZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Before you can train your model, \n",
        "with open(\"seqs.txt\", \"r\") as source:\n",
        "    with open(\"formatted.txt\", \"w\") as destination:\n",
        "        for i,seq in enumerate(source):\n",
        "            seq = seq.strip()\n",
        "            if b.is_valid_seq(seq) and len(seq) < 275: \n",
        "                formatted = \",\".join(map(str,b.format_seq(seq)))\n",
        "                destination.write(formatted)\n",
        "                destination.write('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VqkMywUYzkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "bucket_op = b.bucket_batch_pad(\"formatted.txt\", interval=1000) # Large interval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka8HSXan7M-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    batch = sess.run(bucket_op)\n",
        "    \n",
        "print(batch)\n",
        "print(batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGn5Eg-e7Z3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_hidden, x_placeholder, batch_size_placeholder, seq_length_placeholder, initial_state_placeholder = (\n",
        "    b.get_rep_ops())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvgIoAZt7cRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_placeholder = tf.placeholder(tf.float32, shape=[None,1], name=\"y\")\n",
        "initializer = tf.contrib.layers.xavier_initializer(uniform=False)\n",
        "\n",
        "with tf.variable_scope(\"top\"):\n",
        "    prediction = tf.contrib.layers.fully_connected(\n",
        "        final_hidden, 1, activation_fn=None, \n",
        "        weights_initializer=initializer,\n",
        "        biases_initializer=tf.zeros_initializer()\n",
        "    )\n",
        "\n",
        "loss = tf.losses.mean_squared_error(y_placeholder, prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ur7TsdQ7eLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate=.001\n",
        "top_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"top\")\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "top_only_step_op = optimizer.minimize(loss, var_list=top_variables)\n",
        "all_step_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cLxGP0O7hgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nonpad_len(batch):\n",
        "    nonzero = batch > 0\n",
        "    lengths = np.sum(nonzero, axis=1)\n",
        "    return lengths\n",
        "\n",
        "nonpad_len(batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8smz6377jck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = [[42]]*batch_size\n",
        "num_iters = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for i in range(num_iters):\n",
        "        batch = sess.run(bucket_op)\n",
        "        length = nonpad_len(batch)\n",
        "        loss_, __, = sess.run([loss, top_only_step_op],\n",
        "                feed_dict={\n",
        "                     x_placeholder: batch,\n",
        "                     y_placeholder: y,\n",
        "                     batch_size_placeholder: batch_size,\n",
        "                     seq_length_placeholder:length,\n",
        "                     initial_state_placeholder:b._zero_state\n",
        "                }\n",
        "        )\n",
        "                  \n",
        "        print(\"Iteration {0}: {1}\".format(i, loss_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UWdQWkVVrdJ",
        "colab_type": "text"
      },
      "source": [
        "# Creating a pipeline for converting sequences to unirep vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnGlG7TH7o1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# time to convert sequences to unirep vectors"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}